{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Bott_Output If Exists Else Create Newly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Bott_Output\" in next(os.walk(os.getcwd()))[1]:\n",
    "    shutil.rmtree(\"Bott_Output\")\n",
    "\n",
    "os.mkdir(\"Bott_Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting All Files List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() + \"/\"\n",
    "\n",
    "directory_list = [cwd + \"Bott/\"]\n",
    "file_list = []\n",
    "\n",
    "while len(directory_list) != 0:\n",
    "\n",
    "    for dl in directory_list:\n",
    "\n",
    "        dir_list = next(os.walk(dl))[1]\n",
    "        for i in range(len(dir_list)):\n",
    "            dir_list[i] = dl + dir_list[i] + \"/\"\n",
    "            \n",
    "        directory_list.extend(dir_list)\n",
    "\n",
    "        file_list.extend([dl+fl for fl in next(os.walk(dl))[2]])\n",
    "\n",
    "        directory_list.remove(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data From The Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"File_Name\": [],\n",
    "        \"Serial\": [],\n",
    "        \"Litho_1\": [],\n",
    "        \"Litho_2\": [],\n",
    "        \"Subject_Code\": [],\n",
    "        \"Examiner_Code\": [],\n",
    "        \"Paper_Serial_No\": [],\n",
    "        \"Additional_Paper_No\": [],\n",
    "        \"Examiner_Marks\": [],\n",
    "        \"Head_Examiner_Marks\": [],\n",
    "        \"Head_Examiner_Code\": []\n",
    "       }\n",
    "\n",
    "split_length = [0, 32, 32, 3, 4, 4, 2, 3, 3, 4]\n",
    "split = np.cumsum(split_length)\n",
    "\n",
    "for fl in file_list:\n",
    "    current_file = open(fl, \"r\")\n",
    "    serial = 1\n",
    "    for line in current_file:\n",
    "        data[\"File_Name\"].append(os.path.basename(fl)[:-4])\n",
    "        data[\"Serial\"].append(f\"{serial:010d}\")\n",
    "        \n",
    "        # iterate through all other keys excpet File_Name and Serial and set their values according to length\n",
    "        key = list(data.keys())[2:]\n",
    "        for i in range(0, len(key)):\n",
    "            if key[i] == \"Litho_1\" or key[i] == \"Litho_2\":\n",
    "                data[key[i]].append(line[split[i]:split[i+1]].replace(\" \", \"0\"))    # replacing <space> with 0 in Litho\n",
    "            else:\n",
    "                data[key[i]].append(line[split[i]:split[i+1]])\n",
    "        serial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"Bott_Output/All_Bott.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate Duplicate Bott Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_bott = df[df.duplicated([\"Litho_1\", \"Litho_2\"])]\n",
    "\n",
    "df = df.drop(duplicate_bott.index)\n",
    "\n",
    "duplicate_bott.to_csv(\"Bott_Output/Duplicate_Bott.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Column Written_Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examiner_marks = df[\"Examiner_Marks\"]\n",
    "head_examiner_marks = df[\"Head_Examiner_Marks\"]\n",
    "\n",
    "marks = np.array([j if j != '   ' else i for i, j in zip(examiner_marks, head_examiner_marks)])\n",
    "\n",
    "df[\"Written_Marks\"] = marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate Invalid Written_Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_numeric = lambda number: re.findall(r\"([0][0-9][0-9])|([1][0][0])\", number)\n",
    "is_numeric = lambda number: re.findall(r\"([0][0-9][0-9])|([1][0][0])|(^ [0-9][0-9])\", number)\n",
    "\n",
    "invalid_marks = [True if len(is_numeric(m)) == 0 else False for m in df[\"Written_Marks\"]]\n",
    "\n",
    "invalid_marks = df[invalid_marks]\n",
    "\n",
    "df = df.drop(invalid_marks.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_marks = invalid_marks[[\"File_Name\", \"Serial\", \"Examiner_Code\", \"Head_Examiner_Code\", \"Examiner_Marks\", \"Head_Examiner_Marks\", \"Written_Marks\"]]\n",
    "\n",
    "invalid_marks = invalid_marks.sort_values([\"File_Name\", \"Serial\"])\n",
    "\n",
    "invalid_marks[\"File_Name\"][invalid_marks[\"File_Name\"].duplicated()] = \"\"\n",
    "\n",
    "invalid_marks.to_excel(\"Bott_Output/Invalid_Marks_Report.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate Unmatched Litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_litho = df[df[\"Litho_1\"] != df[\"Litho_2\"]]\n",
    "\n",
    "df = df.drop(unmatched_litho.index)\n",
    "\n",
    "unmatched_litho[\"File_Name\"][unmatched_litho[\"File_Name\"].duplicated()] = \"\"\n",
    "\n",
    "unmatched_litho.to_excel(\"Bott_Output/Unmatched_Litho_Bott_Report.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Bott_Output/Bott.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
